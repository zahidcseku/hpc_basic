{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beyond Your Local Machine: Leveraging HPC Clusters for Big Data ML Training\n",
    "\n",
    "**LinkedIn**: \n",
    "\n",
    "**Medium**: \n",
    "\n",
    "This notebook contains code corresponds to the article above. \n",
    "\n",
    "Imagine we are working on a social media analysis project. We have two datasets:\n",
    "\n",
    "1. An unlabeled dataset (**`test_data`**) (https://www.kaggle.com/datasets/sudishbasnet/truthseekertwitterdataset2023?select=Twitter+Analysis.csv) containing 60,000 rows, where each row represents a social media user with multiple features.\n",
    "2. A labeled dataset (**`train_data`**) (https://www.kaggle.com/datasets/danieltreiman/twitter-human-bots-dataset) with 25,000 rows.\n",
    "\n",
    "Our task is to label the instances in `test_data` using the $k$-nearest neighbors algorithm based on the `train_data`. Here's a simplified Python snippet of what this process might look like:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
